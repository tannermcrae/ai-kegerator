{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "Use this notebook to convert videos into jpgs and annotate . Opencv comes pre-compiled through homebrew which is way easier than compiling by hand. Install homebrew and then run 'brew install opencv@2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split videos to file. \n",
    "Convert each video file into images and name them as sequential numbers. This will make it easy to annotate them which you'll see how to do once we have the image files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def video_to_frames(video, path_output_dir):\n",
    "\n",
    "    # extract frames from a video and save to directory as 'x.png' where \n",
    "    # x is the frame index\n",
    "    vidcap = cv2.VideoCapture(video)\n",
    "    count = 0\n",
    "    while vidcap.isOpened():\n",
    "        success, image = vidcap.read()\n",
    "        if success:\n",
    "            # Add padding on these image files so that 10 does't convert to 1 and erase images. \n",
    "            cv2.imwrite(os.path.join(path_output_dir, '{0:05d}.jpg'.format(count)), image)\n",
    "            count += 1\n",
    "        else:\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "    vidcap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_video_dir = './movies/sideview/'\n",
    "output_dir_base = './data/sideview/img/'\n",
    "\n",
    "# Iterate through every file in the video directory\n",
    "for file in os.listdir(path_to_video_dir):\n",
    "    # Append the filename to the path and create the directory structure if doesn't exist\n",
    "    output_dir = os.path.join(output_dir_base, file.split('.')[0])\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    # Split every video into images and dump into created directories. \n",
    "    video_to_frames(os.path.join(path_to_video_dir, file), output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate Files\n",
    "At this point, you should have a bunch of image files dumped into the directories we just created. Now we need to annotate them. At the heart of the problem, we're just trying to determine if the glass is full or not. This means we only have two classifications: Full or not full. Because we video'd the cuups while they were being filled, there's a point in the video where the glass changes state from not full to full. We will locate that point manually and note the image number that this change happens. Once we have that number, we'll run the code below to prepend our classification to the file name and use it to annotate these files when we pipe it into the model for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prefix_to_files(dir_path, empty_cutoff, output_dir):\n",
    "    # Filter out the hidden files and directories like .DStore \n",
    "    images = filter( lambda f: not f.startswith('.'), os.listdir(dir_path))\n",
    "    \n",
    "    # create_naming_schema\n",
    "    for i, img_name in enumerate(images):\n",
    "        filepath = os.path.join(dir_path, img_name)\n",
    "        # We want the image_src directory to make the name unique since each directory would \n",
    "        # Have empty_00000.jpg for example\n",
    "        img_src = dir_path.split('/')[-1]\n",
    "        prefix = 'empty' if i <= empty_cutoff else 'full'\n",
    "        new_filename = '{}_{}_{}'.format(prefix, img_src, img_name)\n",
    "        new_filepath = os.path.join(output_dir, new_filename)\n",
    "        os.rename(filepath, new_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prefix annotation to file names\n",
    "This step requires some manual work. Locate the point where the cup becomes full and input it into the add_prefix_to_files() function above. Since each directory has a different cutoff, it's easier to switch the directory path and index then re-run the code below every time for each directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_path = './data/sideview/img/sideview_6'\n",
    "# output_dir = './data/sideview/annotated'\n",
    "# empty_cutoff = 384\n",
    "\n",
    "# add_prefix_to_files(dir_path, empty_cutoff, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate .rec files to use for mxnet model\n",
    "Below we will split up the files annotated previously into a training and validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {\n",
    "    'empty': [],\n",
    "    'full': []\n",
    "}\n",
    "\n",
    "class_to_idx = {\n",
    "    'empty': 0,\n",
    "    'full': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take all the images we've annotated, pull their annotations from the filename, and sort them into their corresponding category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty 980\n",
      "full 1167\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data/sideview/annotated'\n",
    "# Get files from directory and ignore hidden files like .DS files\n",
    "names = filter( lambda f: not f.startswith('.'), os.listdir(data_dir))\n",
    "counter = 0\n",
    "for fn in names:\n",
    "    arr = fn.split('_')\n",
    "    category = arr[0]\n",
    "    class_map[category].append({\n",
    "        'idx': counter,\n",
    "        'label': class_to_idx[category],\n",
    "        'filename': fn,\n",
    "    })\n",
    "    counter += 1\n",
    "    \n",
    "for k in class_map:\n",
    "    print(k, len(class_map[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle the images so that our batches when training the model have an even distribution of different types of training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "for k in class_map:\n",
    "    random.shuffle(class_map[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_lst(image_arr, base_dir, file_path):\n",
    "    with open(file_path, 'w') as f:\n",
    "        count = 0\n",
    "        for img in image_arr:\n",
    "            label = img['label']\n",
    "            img_path = os.path.join(base_dir, img['filename'])\n",
    "            new_line = '\\t'.join([str(count), str(label), str(img_path)])\n",
    "            new_line += '\\n'\n",
    "            f.write(new_line)\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten the items from each class into one big dataset adn split it up 80/20 for training and validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get full dataset\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "full_dataset = flatten([class_map[k] for k in class_map])\n",
    "random.shuffle(full_dataset)\n",
    "\n",
    "train = (0, int(len(full_dataset) * 0.8))\n",
    "validation = (int(len(full_dataset) * 0.8), int(len(full_dataset) * 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1717\n"
     ]
    }
   ],
   "source": [
    "train_set = full_dataset[train[0]: train[1]]\n",
    "validation_set = full_dataset[validation[0]: validation[1]]\n",
    "print(len(train_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate lst files\n",
    "The lst file will be used by the im2rec.py script mxnet provides in order to create the rec files that mxnet will use as input into the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./data/train'):\n",
    "    os.makedirs('./data/train')\n",
    "    \n",
    "write_lst(train_set, data_dir, './data/train/train.lst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./data/validation'):\n",
    "    os.makedirs('./data/validation')\n",
    "    \n",
    "write_lst(validation_set, './data/img', './data/validation/validation.lst')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run generate_rec.sh\n",
    "this script will generate rec file based on lst for different dataset\n",
    "\n",
    "* python3 im2rec.py ./data/train . --center-crop True --resize 512 --pack-label True\n",
    "* python3 im2rec.py ./data/validation . --center-crop True --resize 512 --pack-label True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
